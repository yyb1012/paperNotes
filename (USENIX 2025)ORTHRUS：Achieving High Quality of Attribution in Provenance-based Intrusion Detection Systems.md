# 1. 之前工作的不足
## 归因质量(Quality of Attribution)差
归因质量：系统监测到攻击之后，能否指出:
- 攻击发生的根因是哪些对象(如文件、进程)
- 攻击是如何一步步进行的
- 其他检测出来的信息是不是真的有用    
归因质量高，即**更容易理解攻击发生了什么，不用处理一堆垃圾信息**。
## 现有方法夸大了攻击节点的范围
- 邻域法：攻击节点附近的节点也算进攻击范围
- 批处理法：系统会处理一批事件，并为整个批次计算异常分数(#[[(S&P 2024)KAIROS：Practical Intrusion Detection Investigation using Whole-system Provenance]])
- 源节点法：攻击的源节点会被识别出来，而所有后代节点都被视为恶意

## 本文目标
- 在高准确率的情况下，显著提高归因质量，减少所需检查的数据量
# 2. ORTHRUS架构
![[Pasted image 20250714160610.png]]
## 2.1 图构建

| Logs | Attributes        |
| ---- | ----------------- |
| 进程   | 名称、命令(cmd)        |
| 文件   | 路径                |
| 网络流  | (源/目的)端口、(源/目的)地址 |
| 事件   | 主体、对象、事件类型、事件戳    |
### 因果保留约简(Causality Preserved Reduction,2016)
比如$A \rightarrow B \rightarrow C$,$A \rightarrow C$.删除AC后，A还是能从B到C，因此AC这条边是冗余的

## 2.2 边特征化
### 特征提取
![[Pasted image 20250714163226.png]]
### 层次间关系捕捉
为保证语义相近在向量空间层次相近，Word2vec模型采用Skip-gram的训练方式训练模型。目标是给定一个词，预测出他的"上下文词"。
Skip-gram步骤：
- /var/log/nginx/error.log → ["var", "log", "nginx", "error", "log"]
- 训练：对每个词，用它去预测周围词(窗口大小为k)：
		输入"nginx"，模型要预测"log", "error"
		多次迭代后，"相似路径/命令"会形成相似向量
- 求均值：对于一个完整路径/命令行，把每个词的向量平均，作为该节点属性的嵌入向量。
## 2.3 时序图学习
编码器-解码器结构，时序处理模块更换为了BiLSTM。
## 2.4 异常检测策略
### 自动阈值确定
计算训练数据中所有边的重建误差，采用3$\sigma$原则
### 异常节点聚类
将连接到至少一条异常边的节点标记为异常节点，但这批节点里不全是攻击行为，有些是罕见但是无害的异常行为(冷启动、罕见系统调用)。因此采用K-means算法：
- 重构误差更大、行为差异大 $\rightarrow$ 高概率恶意，保留，构建攻击图
- 重建误差中等、分布分散 $\rightarrow$可能为良性异常，被忽略
总体而言，先通过GNN构建误差，做异常检测；再通过聚类，在异常中再做一次筛选

# 数据集
DARPA E3，E5
